import requests
import os
from urllib.parse import urlparse, parse_qs
import urllib3
from tqdm import tqdm
import time

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# â–¶ â‘  æŠŠ Meta é‚®ä»¶é‡Œçš„â€œå¸¦ç­¾åâ€é“¾æŽ¥è´´åˆ°è¿™é‡Œ
base_url = 'https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiZzYwYW00YmRwYm8zMWJzeTlka2F1YmJwIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDU3OTE0MX19fV19&Signature=YCv9VbZlDWsLF29ERRSmwNQCEC11rBtsIfqE2GCCotA%7E6D32fnagkwIut3t1zWuRaCuLviljD3yLzb1CgSCejZJe%7ElFfsTHprnd3bPUxPQxMXrX4l39sEZQX1C7KA47ucpuSbiw6qRV1Nt5F8TyURlt1AdzBQNlySEd0HN3K6sEDNSOGqgPtROZYUCb2PoP6B3DTHrXkDj%7EJyjn%7EfI7PBvPsgy683WZFv8J1F7ANhpErDiK7OnlxV0avpXJuTLeI%7EojDqRzcvQTHSIIQN3f83xj0nU3N%7EvsnKdVGeJ9s-9weUrvsxh5ZmZStb6i-0kEMBYF0mCmE9PbSnoIqBa43kA__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1275803444059541'

# â–¶ â‘¡ Llama-2-7B-Chat æ‰€éœ€æ–‡ä»¶
files_to_download = [
    "consolidated.00.pth",
    "consolidated.01.pth",
    "params.json",
    "tokenizer.model",
    "checklist.chk",
]

# â–¶ â‘¢ ä¸‹è½½åˆ°å“ªé‡Œ
target_dir = r"C:\Users\Administrator\llama_models\Llama-2-7b-chat"

# ç»Ÿä¸€é…ç½®
CHUNK_SIZE  = 64 * 1024       # 64 KB
TIMEOUT     = 300             # 5 min
MAX_RETRIES = 5
RETRY_DELAY = 5               # ç§’


def get_file_size(url):
    try:
        print(f"  ðŸ” æ£€æŸ¥URL: {url}")
        r = requests.head(url, verify=False, timeout=30)
        print(f"  ðŸ“Š çŠ¶æ€ç : {r.status_code}")
        if r.status_code == 200:
            size = int(r.headers.get("content-length", 0))
            print(f"  ðŸ“ æ–‡ä»¶å¤§å°: {size:,} bytes")
            return size
        else:
            print(f"  âŒ HTTPé”™è¯¯: {r.status_code}")
            return 0
    except Exception as e:
        print(f"  âŒ è¯·æ±‚é”™è¯¯: {e}")
        return 0


def download_file_with_resume(url, filepath, max_retries=MAX_RETRIES):
    resume_pos = os.path.getsize(filepath) if os.path.exists(filepath) else 0
    total_size = get_file_size(url)
    if total_size == 0:
        print(f"âŒ æ— æ³•èŽ·å–æ–‡ä»¶å¤§å°: {os.path.basename(filepath)}")
        return False
    if resume_pos >= total_size:
        print(f"âœ… å·²å®Œæ•´: {os.path.basename(filepath)}")
        return True

    headers = {"Range": f"bytes={resume_pos}-"} if resume_pos else {}
    retry = 0
    while retry < max_retries:
        try:
            print(f"ðŸ“¥ {os.path.basename(filepath)}  (å°è¯• {retry+1}/{max_retries})")
            sess = requests.Session()
            sess.mount(
                "https://",
                requests.adapters.HTTPAdapter(pool_connections=10, pool_maxsize=20, max_retries=3),
            )
            resp = sess.get(url, headers=headers, stream=True, timeout=(30, TIMEOUT), verify=False)
            resp.raise_for_status()

            # è¿›åº¦æ¡
            pbar = tqdm(
                total=total_size,
                initial=resume_pos,
                unit="B",
                unit_scale=True,
                desc=os.path.basename(filepath),
                ascii=True,
            )
            mode = "ab" if resume_pos else "wb"
            with open(filepath, mode) as f:
                for chunk in resp.iter_content(chunk_size=CHUNK_SIZE):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            pbar.close()

            if os.path.getsize(filepath) == total_size:
                print(f"âœ… å®Œæˆ: {os.path.basename(filepath)}")
                return True
            else:
                print("âš ï¸  æ–‡ä»¶å°ºå¯¸ä¸ç¬¦ï¼Œé‡è¯•â€¦")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        retry += 1
        print(f"â³ {RETRY_DELAY} ç§’åŽé‡è¯•â€¦")
        time.sleep(RETRY_DELAY)
        resume_pos = os.path.getsize(filepath) if os.path.exists(filepath) else 0
        headers["Range"] = f"bytes={resume_pos}-"
    return False


def main():
    print("ðŸš€ å¼€å§‹ä¸‹è½½ Llama-2-7B-Chatï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰")
    print(f"ðŸ“ ç›®å½•: {target_dir}")
    print(f"âš™ï¸  å—={CHUNK_SIZE//1024}KB, è¶…æ—¶={TIMEOUT}s, é‡è¯•={MAX_RETRIES}")

    os.makedirs(target_dir, exist_ok=True)

    # â–¶ â‘£ ä»…æ”¹è¿™é‡Œå³å¯æ¢æ¨¡åž‹
    MODEL_DIR = "llama-2-7b-chat"  # ä½¿ç”¨æµ‹è¯•ç¡®è®¤çš„æ­£ç¡®æ ¼å¼
    possible_formats = [
        f"/{MODEL_DIR}/{{}}?",  # è¿™æ˜¯æµ‹è¯•ç¡®è®¤æœ‰æ•ˆçš„æ ¼å¼ï¼
    ]

    success = 0
    for i, fname in enumerate(files_to_download, 1):
        print(f"\nðŸ“‹ æ–‡ä»¶ {i}/{len(files_to_download)}: {fname}")
        path = os.path.join(target_dir, fname)
        ok = False
        for fmt in possible_formats:
            url = base_url.replace("/*?", fmt.format(fname))
            print(f"ðŸ”— è¯• URL: {fmt}")
            if download_file_with_resume(url, path):
                ok = True
                success += 1
                break
            else:
                print(f"âŒ URL å¤±è´¥: {fmt}")
        if not ok:
            print(f"ðŸ’¥ å…¨éƒ¨ URL å¤±è´¥: {fname}")
        print("-" * 80)

    print(f"\nðŸ“Š æˆåŠŸ {success}/{len(files_to_download)}")
    if success == len(files_to_download):
        print("ðŸŽ‰ å…¨éƒ¨ä¸‹è½½å®Œæˆï¼")


if __name__ == "__main__":
    main()
