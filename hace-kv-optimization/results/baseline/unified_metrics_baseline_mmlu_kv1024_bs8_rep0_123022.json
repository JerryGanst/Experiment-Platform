{
  "experiment_id": "baseline_mmlu_kv1024_bs8_rep0_123022",
  "timestamp": "2025-06-08T12:34:52.078230",
  "performance": {
    "success": true,
    "ttft_ms": 3922.121047973633,
    "tpot_ms": 958.7298337151022,
    "throughput_tokens_per_sec": 1.030599012827496,
    "total_time_sec": 248.39922881126404,
    "tokens_generated": 256,
    "model_name": "NousResearch/Llama-2-7b-hf",
    "precision": "fp16",
    "batch_size": 8,
    "kv_cache_length": 1024,
    "max_new_tokens": 256,
    "use_baseline": true,
    "dataset": "mmlu"
  },
  "gpu": {
    "total_devices": 1,
    "device_0": {
      "peak_memory_mb": 9904.05712890625,
      "average_memory_mb": 9187.905849689349,
      "sample_count": 2198
    },
    "total_peak_memory_mb": 9904.05712890625
  },
  "system": {
    "peak_cpu_percent": 19.1,
    "average_cpu_percent": 8.39672131147541,
    "peak_memory_percent": 45.4,
    "peak_memory_used_gb": 29.00757598876953,
    "sample_count": 244
  },
  "monitoring_duration": 248.44736218452454
}