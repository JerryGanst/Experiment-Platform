2025-06-08 12:07:58,957 - __main__ - INFO - Starting baseline experiment suite
2025-06-08 12:07:58,958 - __main__ - INFO - Arguments: Namespace(model_name='NousResearch/Llama-2-7b-hf', datasets='mmlu', kv_cache_lengths='512,1024,2048', batch_sizes='1,4,8', max_new_tokens=256, repetitions=3, output_dir='./results/baseline', log_level='INFO', seed=42)
2025-06-08 12:07:58,990 - __main__ - INFO - Random seed set to 42
2025-06-08 12:07:58,990 - __main__ - INFO - Total number of baseline experiment configurations to run: 27
2025-06-08 12:07:58,992 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 512, Batch: 1
2025-06-08 12:07:58,992 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs1_rep0_120758
2025-06-08 12:07:58,992 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:07:58,992 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs1_rep0_120758
2025-06-08 12:07:58,993 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:07:58,993 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:07:58,993 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:08:01,154 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:08:07,494 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-08 12:08:07,494 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:08:08,303 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:08:08,304 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 512
2025-06-08 12:08:08,304 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:08:08,304 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 512
2025-06-08 12:08:08,304 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:08:08,304 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:08:08,304 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:08:23,300 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:08:23,300 - hace_core.data.dataset_loader - INFO - Preparing 2 samples from mmlu
2025-06-08 12:08:23,301 - hace_core.data.dataset_loader - INFO - Prepared 2 samples successfully
2025-06-08 12:08:23,301 - __main__ - INFO - Preparing batch with size 1...
2025-06-08 12:08:23,305 - __main__ - INFO - Warming up model...
2025-06-08 12:08:27,674 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:08:27,675 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:08:27,675 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:08:27,675 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:08:28,185 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:10:03,099 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 95.42秒
2025-06-08 12:10:03,099 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-08 12:10:03,111 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: ./results/baseline\unified_metrics_baseline_mmlu_kv512_bs1_rep0_120758.json
2025-06-08 12:10:03,112 - __main__ - INFO - Baseline experiment baseline_mmlu_kv512_bs1_rep0_120758 completed successfully
2025-06-08 12:10:03,115 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 512, Batch: 4
2025-06-08 12:10:03,115 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs4_rep0_121003
2025-06-08 12:10:03,115 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:10:03,115 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs4_rep0_121003
2025-06-08 12:10:03,115 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:10:03,116 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:10:03,116 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:10:03,546 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:10:03,556 - accelerate.utils.modeling - INFO - Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - 0: 666910720 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
2025-06-08 12:10:03,891 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:10:04,503 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:10:04,503 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 512
2025-06-08 12:10:04,503 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:10:04,504 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 512
2025-06-08 12:10:04,504 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:10:04,504 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:10:04,504 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:10:12,449 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:10:12,449 - hace_core.data.dataset_loader - INFO - Preparing 8 samples from mmlu
2025-06-08 12:10:12,450 - hace_core.data.dataset_loader - INFO - Prepared 8 samples successfully
2025-06-08 12:10:12,450 - __main__ - INFO - Preparing batch with size 4...
2025-06-08 12:10:12,452 - __main__ - INFO - Warming up model...
2025-06-08 12:12:21,498 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:12:21,498 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:12:21,498 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:12:21,499 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:14:29,246 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:16:07,046 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs4_rep0_121003: probability tensor contains either `inf`, `nan` or element < 0
2025-06-08 12:16:07,046 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: probability tensor contains either `inf`, `nan` or element < 0
2025-06-08 12:16:07,317 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 512, Batch: 8
2025-06-08 12:16:07,317 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs8_rep0_121607
2025-06-08 12:16:07,317 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:16:07,317 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs8_rep0_121607
2025-06-08 12:16:07,317 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:16:07,317 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:16:07,318 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:16:07,874 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:16:08,531 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-08 12:16:08,532 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:16:09,167 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:16:09,167 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 512
2025-06-08 12:16:09,168 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:16:09,168 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 512
2025-06-08 12:16:09,168 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:16:09,168 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:16:09,168 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:16:16,769 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:16:16,769 - hace_core.data.dataset_loader - INFO - Preparing 16 samples from mmlu
2025-06-08 12:16:16,770 - hace_core.data.dataset_loader - INFO - Prepared 16 samples successfully
2025-06-08 12:16:16,770 - __main__ - INFO - Preparing batch with size 8...
2025-06-08 12:16:16,774 - __main__ - INFO - Warming up model...
2025-06-08 12:16:25,795 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:16:25,795 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:16:25,796 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:16:25,796 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:16:28,566 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:21:45,862 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 320.07秒
2025-06-08 12:21:45,863 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-08 12:21:45,882 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: ./results/baseline\unified_metrics_baseline_mmlu_kv512_bs8_rep0_121607.json
2025-06-08 12:21:45,883 - __main__ - INFO - Baseline experiment baseline_mmlu_kv512_bs8_rep0_121607 completed successfully
2025-06-08 12:21:45,885 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 1024, Batch: 1
2025-06-08 12:21:45,886 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs1_rep0_122145
2025-06-08 12:21:45,886 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:21:45,886 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs1_rep0_122145
2025-06-08 12:21:45,886 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:21:45,886 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:21:45,886 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:21:46,806 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:21:48,467 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-08 12:21:48,468 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:21:49,101 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:21:49,101 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 1024
2025-06-08 12:21:49,101 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:21:49,101 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 1024
2025-06-08 12:21:49,101 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:21:49,102 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:21:49,102 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:21:57,023 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:21:57,023 - hace_core.data.dataset_loader - INFO - Preparing 2 samples from mmlu
2025-06-08 12:21:57,023 - hace_core.data.dataset_loader - INFO - Prepared 2 samples successfully
2025-06-08 12:21:57,023 - __main__ - INFO - Preparing batch with size 1...
2025-06-08 12:21:57,026 - __main__ - INFO - Warming up model...
2025-06-08 12:22:01,885 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:22:01,885 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:22:01,885 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:22:01,886 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:22:02,828 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:25:06,835 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 184.95秒
2025-06-08 12:25:06,836 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-08 12:25:06,863 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: ./results/baseline\unified_metrics_baseline_mmlu_kv1024_bs1_rep0_122145.json
2025-06-08 12:25:06,863 - __main__ - INFO - Baseline experiment baseline_mmlu_kv1024_bs1_rep0_122145 completed successfully
2025-06-08 12:25:06,865 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 1024, Batch: 4
2025-06-08 12:25:06,866 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs4_rep0_122506
2025-06-08 12:25:06,866 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:25:06,866 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs4_rep0_122506
2025-06-08 12:25:06,866 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:25:06,866 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:25:06,866 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:25:07,404 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:25:08,049 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-08 12:25:08,049 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:25:08,620 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:25:08,620 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 1024
2025-06-08 12:25:08,620 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:25:08,620 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 1024
2025-06-08 12:25:08,620 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:25:08,620 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:25:08,620 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:25:15,467 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:25:15,468 - hace_core.data.dataset_loader - INFO - Preparing 8 samples from mmlu
2025-06-08 12:25:15,468 - hace_core.data.dataset_loader - INFO - Prepared 8 samples successfully
2025-06-08 12:25:15,468 - __main__ - INFO - Preparing batch with size 4...
2025-06-08 12:25:15,471 - __main__ - INFO - Warming up model...
2025-06-08 12:25:24,039 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:25:24,040 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:25:24,040 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:25:24,040 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:25:26,380 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:30:22,790 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 298.75秒
2025-06-08 12:30:22,790 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-08 12:30:22,835 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: ./results/baseline\unified_metrics_baseline_mmlu_kv1024_bs4_rep0_122506.json
2025-06-08 12:30:22,836 - __main__ - INFO - Baseline experiment baseline_mmlu_kv1024_bs4_rep0_122506 completed successfully
2025-06-08 12:30:22,839 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 1024, Batch: 8
2025-06-08 12:30:22,839 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs8_rep0_123022
2025-06-08 12:30:22,839 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:30:22,839 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs8_rep0_123022
2025-06-08 12:30:22,839 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:30:22,839 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:30:22,839 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:30:23,377 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:30:24,626 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-08 12:30:24,626 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-08 12:30:25,668 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-08 12:30:25,668 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 1024
2025-06-08 12:30:25,668 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-08 12:30:25,668 - hace_core.models.model_loader - INFO - Model llama configured successfully for KV cache length: 1024
2025-06-08 12:30:25,668 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-08 12:30:25,669 - __main__ - INFO - Loading dataset mmlu...
2025-06-08 12:30:25,669 - hace_core.data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-08 12:30:34,371 - hace_core.data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-08 12:30:34,371 - hace_core.data.dataset_loader - INFO - Preparing 16 samples from mmlu
2025-06-08 12:30:34,372 - hace_core.data.dataset_loader - INFO - Prepared 16 samples successfully
2025-06-08 12:30:34,372 - __main__ - INFO - Preparing batch with size 8...
2025-06-08 12:30:34,375 - __main__ - INFO - Warming up model...
2025-06-08 12:30:43,630 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-08 12:30:43,630 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-08 12:30:43,630 - __main__ - INFO - Starting performance measurement...
2025-06-08 12:30:43,631 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-08 12:30:47,553 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-08 12:34:52,031 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 248.40秒
2025-06-08 12:34:52,031 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-08 12:34:52,079 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: ./results/baseline\unified_metrics_baseline_mmlu_kv1024_bs8_rep0_123022.json
2025-06-08 12:34:52,080 - __main__ - INFO - Baseline experiment baseline_mmlu_kv1024_bs8_rep0_123022 completed successfully
2025-06-08 12:34:52,082 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 2048, Batch: 1
2025-06-08 12:34:52,083 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs1_rep0_123452
2025-06-08 12:34:52,083 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:52,083 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs1_rep0_123452
2025-06-08 12:34:52,083 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:52,083 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:52,083 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:52,420 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:52,443 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:52,443 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs1_rep0_123452: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:52,443 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:52,444 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 2048, Batch: 4
2025-06-08 12:34:52,444 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs4_rep0_123452
2025-06-08 12:34:52,444 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:52,444 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs4_rep0_123452
2025-06-08 12:34:52,445 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:52,445 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:52,445 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:52,734 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:52,763 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -164806246: [-164806246]
2025-06-08 12:34:52,763 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs4_rep0_123452: Trying to create tensor with negative dimension -164806246: [-164806246]
2025-06-08 12:34:52,763 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -164806246: [-164806246]
2025-06-08 12:34:52,764 - __main__ - INFO - Running baseline: Rep 1/3, Dataset: mmlu, KV_Len: 2048, Batch: 8
2025-06-08 12:34:52,764 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs8_rep0_123452
2025-06-08 12:34:52,764 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:52,764 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs8_rep0_123452
2025-06-08 12:34:52,764 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:52,764 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:52,765 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:53,032 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:53,053 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,054 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs8_rep0_123452: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,054 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,054 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 512, Batch: 1
2025-06-08 12:34:53,055 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs1_rep1_123453
2025-06-08 12:34:53,055 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:53,055 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs1_rep1_123453
2025-06-08 12:34:53,055 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:53,055 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:53,055 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:53,318 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:53,340 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,340 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs1_rep1_123453: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,340 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:53,341 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 512, Batch: 4
2025-06-08 12:34:53,341 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs4_rep1_123453
2025-06-08 12:34:53,341 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:53,341 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs4_rep1_123453
2025-06-08 12:34:53,341 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:53,341 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:53,341 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:53,610 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:53,632 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -170810982: [-170810982]
2025-06-08 12:34:53,632 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs4_rep1_123453: Trying to create tensor with negative dimension -170810982: [-170810982]
2025-06-08 12:34:53,632 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -170810982: [-170810982]
2025-06-08 12:34:53,634 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 512, Batch: 8
2025-06-08 12:34:53,634 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs8_rep1_123453
2025-06-08 12:34:53,634 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:53,634 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs8_rep1_123453
2025-06-08 12:34:53,634 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:53,634 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:53,634 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:53,906 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:53,927 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:53,927 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs8_rep1_123453: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:53,928 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:53,928 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 1024, Batch: 1
2025-06-08 12:34:53,928 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs1_rep1_123453
2025-06-08 12:34:53,929 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:53,929 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs1_rep1_123453
2025-06-08 12:34:53,929 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:53,929 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:53,929 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:54,199 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:54,219 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -102301286: [-102301286]
2025-06-08 12:34:54,220 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs1_rep1_123453: Trying to create tensor with negative dimension -102301286: [-102301286]
2025-06-08 12:34:54,220 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -102301286: [-102301286]
2025-06-08 12:34:54,221 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 1024, Batch: 4
2025-06-08 12:34:54,221 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs4_rep1_123454
2025-06-08 12:34:54,221 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:54,221 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs4_rep1_123454
2025-06-08 12:34:54,221 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:54,221 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:54,221 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:54,551 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:54,572 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:54,572 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs4_rep1_123454: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:54,572 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:54,573 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 1024, Batch: 8
2025-06-08 12:34:54,573 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs8_rep1_123454
2025-06-08 12:34:54,573 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:54,573 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs8_rep1_123454
2025-06-08 12:34:54,574 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:54,574 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:54,574 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:54,877 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:54,910 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:54,910 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs8_rep1_123454: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:54,910 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:54,911 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 2048, Batch: 1
2025-06-08 12:34:54,911 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs1_rep1_123454
2025-06-08 12:34:54,911 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:54,911 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs1_rep1_123454
2025-06-08 12:34:54,911 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:54,911 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:54,912 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:55,292 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:55,316 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:55,316 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs1_rep1_123454: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:55,316 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:55,317 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 2048, Batch: 4
2025-06-08 12:34:55,317 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs4_rep1_123455
2025-06-08 12:34:55,317 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:55,317 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs4_rep1_123455
2025-06-08 12:34:55,317 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:55,318 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:55,318 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:55,593 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:55,614 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:55,615 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs4_rep1_123455: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:55,615 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -86091366: [-86091366]
2025-06-08 12:34:55,616 - __main__ - INFO - Running baseline: Rep 2/3, Dataset: mmlu, KV_Len: 2048, Batch: 8
2025-06-08 12:34:55,616 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs8_rep1_123455
2025-06-08 12:34:55,616 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:55,616 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs8_rep1_123455
2025-06-08 12:34:55,616 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:55,616 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:55,616 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:55,884 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:55,906 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -165527142: [-165527142]
2025-06-08 12:34:55,906 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs8_rep1_123455: Trying to create tensor with negative dimension -165527142: [-165527142]
2025-06-08 12:34:55,906 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -165527142: [-165527142]
2025-06-08 12:34:55,907 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 512, Batch: 1
2025-06-08 12:34:55,907 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs1_rep2_123455
2025-06-08 12:34:55,907 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:55,908 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs1_rep2_123455
2025-06-08 12:34:55,908 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:55,908 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:55,908 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:56,177 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:56,197 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:56,197 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs1_rep2_123455: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:56,197 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -75507302: [-75507302]
2025-06-08 12:34:56,198 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 512, Batch: 4
2025-06-08 12:34:56,198 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs4_rep2_123456
2025-06-08 12:34:56,198 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:56,198 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs4_rep2_123456
2025-06-08 12:34:56,199 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:56,199 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:56,199 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:56,473 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:56,495 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:56,496 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs4_rep2_123456: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:56,496 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:56,497 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 512, Batch: 8
2025-06-08 12:34:56,497 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv512_bs8_rep2_123456
2025-06-08 12:34:56,497 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:56,497 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv512_bs8_rep2_123456
2025-06-08 12:34:56,497 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:56,497 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:56,497 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:56,978 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:56,999 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -102661734: [-102661734]
2025-06-08 12:34:56,999 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv512_bs8_rep2_123456: Trying to create tensor with negative dimension -102661734: [-102661734]
2025-06-08 12:34:56,999 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -102661734: [-102661734]
2025-06-08 12:34:57,000 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 1024, Batch: 1
2025-06-08 12:34:57,000 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs1_rep2_123457
2025-06-08 12:34:57,000 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:57,001 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs1_rep2_123457
2025-06-08 12:34:57,001 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:57,001 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:57,001 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:57,278 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:57,687 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -80225894: [-80225894]
2025-06-08 12:34:57,687 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs1_rep2_123457: Trying to create tensor with negative dimension -80225894: [-80225894]
2025-06-08 12:34:57,687 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -80225894: [-80225894]
2025-06-08 12:34:57,688 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 1024, Batch: 4
2025-06-08 12:34:57,688 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs4_rep2_123457
2025-06-08 12:34:57,688 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:57,688 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs4_rep2_123457
2025-06-08 12:34:57,688 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:57,689 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:57,689 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:57,966 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:58,005 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -140885606: [-140885606]
2025-06-08 12:34:58,005 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs4_rep2_123457: Trying to create tensor with negative dimension -140885606: [-140885606]
2025-06-08 12:34:58,005 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -140885606: [-140885606]
2025-06-08 12:34:58,006 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 1024, Batch: 8
2025-06-08 12:34:58,006 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv1024_bs8_rep2_123458
2025-06-08 12:34:58,006 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:58,006 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv1024_bs8_rep2_123458
2025-06-08 12:34:58,006 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:58,006 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:58,006 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:58,279 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:58,300 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:58,300 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv1024_bs8_rep2_123458: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:58,300 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -92077670: [-92077670]
2025-06-08 12:34:58,301 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 2048, Batch: 1
2025-06-08 12:34:58,301 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs1_rep2_123458
2025-06-08 12:34:58,301 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:58,301 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs1_rep2_123458
2025-06-08 12:34:58,302 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:58,302 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:58,302 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:58,571 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:58,591 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:58,591 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs1_rep2_123458: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:58,591 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -140365414: [-140365414]
2025-06-08 12:34:58,592 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 2048, Batch: 4
2025-06-08 12:34:58,592 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs4_rep2_123458
2025-06-08 12:34:58,592 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:58,592 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs4_rep2_123458
2025-06-08 12:34:58,592 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:58,592 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:58,593 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:58,906 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:58,935 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:58,935 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs4_rep2_123458: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:58,935 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -113966694: [-113966694]
2025-06-08 12:34:58,936 - __main__ - INFO - Running baseline: Rep 3/3, Dataset: mmlu, KV_Len: 2048, Batch: 8
2025-06-08 12:34:58,936 - __main__ - INFO - Starting baseline experiment: baseline_mmlu_kv2048_bs8_rep2_123458
2025-06-08 12:34:58,936 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-08 12:34:58,936 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: baseline_mmlu_kv2048_bs8_rep2_123458
2025-06-08 12:34:58,936 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-08 12:34:58,937 - __main__ - INFO - Loading model and tokenizer...
2025-06-08 12:34:58,937 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-08 12:34:59,211 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 12:34:59,233 - hace_core.models.model_loader - ERROR - Error loading model: Trying to create tensor with negative dimension -130563686: [-130563686]
2025-06-08 12:34:59,233 - __main__ - ERROR - Error during baseline experiment baseline_mmlu_kv2048_bs8_rep2_123458: Trying to create tensor with negative dimension -130563686: [-130563686]
2025-06-08 12:34:59,233 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Trying to create tensor with negative dimension -130563686: [-130563686]
2025-06-08 12:34:59,237 - __main__ - INFO - All baseline experiment summaries saved to ./results/baseline\all_baseline_experiments_summary.csv
2025-06-08 12:34:59,238 - __main__ - INFO - Baseline experiment suite finished.
