{
  "experiment_id": "baseline_mmlu_kv512_bs8_rep0_121607",
  "timestamp": "2025-06-08T12:21:45.881338",
  "performance": {
    "success": true,
    "ttft_ms": 2769.8605060577393,
    "tpot_ms": 1244.2939449759092,
    "throughput_tokens_per_sec": 0.799835487466919,
    "total_time_sec": 320.0658185482025,
    "tokens_generated": 256,
    "model_name": "NousResearch/Llama-2-7b-hf",
    "precision": "fp16",
    "batch_size": 8,
    "kv_cache_length": 512,
    "max_new_tokens": 256,
    "use_baseline": true,
    "dataset": "mmlu"
  },
  "gpu": {
    "total_devices": 1,
    "device_0": {
      "peak_memory_mb": 3961.9072265625,
      "average_memory_mb": 3258.4724773456805,
      "sample_count": 2833
    },
    "total_peak_memory_mb": 3961.9072265625
  },
  "system": {
    "peak_cpu_percent": 28.8,
    "average_cpu_percent": 8.355873015873016,
    "peak_memory_percent": 46.7,
    "peak_memory_used_gb": 29.78118896484375,
    "sample_count": 315
  },
  "monitoring_duration": 320.085818529129
}