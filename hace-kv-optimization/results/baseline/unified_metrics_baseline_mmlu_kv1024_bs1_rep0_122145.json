{
  "experiment_id": "baseline_mmlu_kv1024_bs1_rep0_122145",
  "timestamp": "2025-06-08T12:25:06.862434",
  "performance": {
    "success": true,
    "ttft_ms": 942.3863887786865,
    "tpot_ms": 721.5861423342835,
    "throughput_tokens_per_sec": 1.3841664681100467,
    "total_time_sec": 184.9488525390625,
    "tokens_generated": 256,
    "model_name": "NousResearch/Llama-2-7b-hf",
    "precision": "fp16",
    "batch_size": 1,
    "kv_cache_length": 1024,
    "max_new_tokens": 256,
    "use_baseline": true,
    "dataset": "mmlu"
  },
  "gpu": {
    "total_devices": 1,
    "device_0": {
      "peak_memory_mb": 6551.81884765625,
      "average_memory_mb": 6305.8321672648135,
      "sample_count": 1637
    },
    "total_peak_memory_mb": 6551.81884765625
  },
  "system": {
    "peak_cpu_percent": 38.2,
    "average_cpu_percent": 8.44065934065934,
    "peak_memory_percent": 45.0,
    "peak_memory_used_gb": 28.74999237060547,
    "sample_count": 182
  },
  "monitoring_duration": 184.97695231437683
}