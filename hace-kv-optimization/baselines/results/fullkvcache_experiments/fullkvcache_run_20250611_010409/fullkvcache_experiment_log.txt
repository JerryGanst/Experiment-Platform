2025-06-11 01:04:09,775 - __main__ - INFO - Starting FullKVCache experiment suite with run name: fullkvcache_run_20250611_010409
2025-06-11 01:04:09,775 - __main__ - INFO - Arguments: Namespace(model_name='NousResearch/Llama-2-7b-hf', datasets='hotpotqa', kv_cache_lengths='512', batch_sizes='1', max_new_tokens=50, repetitions=1, output_dir='results\\fullkvcache_experiments', log_level='INFO', seed=42, run_name='fullkvcache_run_20250611_010409', enable_scoring=True, is_baseline_run=True)
2025-06-11 01:04:09,776 - __main__ - INFO - Global EXPERIMENT_CONFIG being used: {'model_name_or_path': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'multi_model_experiments': True, 'experiment_models': ['NousResearch/Llama-2-7b-hf', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'mistralai/Mistral-7B-Instruct-v0.3'], 'memory_management': {'auto_max_memory': True, 'manual_max_memory': {0: '23000MB'}, 'memory_buffer_ratio': 0.05, 'force_no_cpu_offload': True}, 'datasets': ['mmlu', 'gsm8k', 'winogrande', 'arc_challenge', 'hellaswag', 'truthful_qa_mc'], 'dataset_subset_size': {'mmlu': 100, 'gsm8k': 100, 'winogrande': None, 'arc_challenge': None, 'hellaswag': None, 'truthful_qa_mc': None, 'pubmed_qa': 100, 'cais/mmlu-zh': 50}, 'kv_cache_lengths': [128, 256, 512, 1024, 2048], 'batch_sizes': [1, 4, 8], 'max_new_tokens': 256, 'repetitions': 3, 'h2o_enabled': True, 'h2o_ratios': [0.1, 0.2, 0.3], 'eviction_strategies': ['attention', 'time_decay', 'hybrid'], 'h2o_kv_cache_lengths': [128, 256, 512, 1024, 2048], 'cake_enabled': True, 'layer_allocation_strategies': ['uniform', 'adaptive', 'attention_based'], 'layer_analysis_configs': {'attention_pattern_analysis': True, 'layer_importance_scoring': True, 'dynamic_allocation': True}, 'cache_budgets': [0.5, 0.7, 0.9], 'cake_kv_cache_lengths': [128, 256, 512, 1024, 2048], 'head_level_optimization': False, 'head_analysis_enabled': False, 'head_selection_strategy': 'top_k', 'head_k_value': 10, 'output_base_dir': 'results', 'enable_monitoring': True, 'monitor_interval': 0.5}
2025-06-11 01:04:09,821 - __main__ - INFO - Random seed set to 42
2025-06-11 01:04:09,822 - __main__ - INFO - Total number of FullKVCache experiment configurations to run: 1
2025-06-11 01:04:09,827 - __main__ - INFO - Running FullKVCache: Rep 1/1, Dataset: hotpotqa, KV_Len: 512, Batch: 1
2025-06-11 01:04:10,140 - __main__ - INFO - Starting FullKVCache experiment: fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410
2025-06-11 01:04:10,243 - __main__ - INFO - 实验前内存清理完成
2025-06-11 01:04:10,245 - hace_core.utils.unified_monitor - INFO - 发现1个GPU设备
2025-06-11 01:04:10,245 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410
2025-06-11 01:04:10,245 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-11 01:04:10,246 - __main__ - INFO - Loading model and tokenizer...
2025-06-11 01:04:10,246 - hace_core.models.model_loader - INFO - Loading model: NousResearch/Llama-2-7b-hf
2025-06-11 01:04:10,247 - hace_core.models.model_loader - INFO - GPU 0: 总显存 24563MB, 自动设置上限 23000MB (缓冲比例: 5.0%)
2025-06-11 01:04:10,247 - hace_core.models.model_loader - INFO - 使用精细显存控制: {0: '23000MB'}
2025-06-11 01:04:44,459 - hace_core.models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-11 01:04:44,461 - hace_core.models.model_loader - INFO - GPU 0 显存使用: 已分配 12.55GB, 已保留 12.55GB
2025-06-11 01:04:54,642 - hace_core.models.model_loader - INFO - Tokenizer loaded successfully
2025-06-11 01:04:54,643 - __main__ - INFO - 模型加载后GPU内存: 13.48GB
2025-06-11 01:04:54,645 - hace_core.models.model_loader - INFO - Configuring model for KV cache length: 512
2025-06-11 01:04:54,646 - hace_core.models.model_loader - INFO - Updated max_position_embeddings from 4096 to 4096
2025-06-11 01:04:54,646 - hace_core.models.model_loader - WARNING - Could not fully configure KV cache length: 'LlamaRotaryEmbedding' object has no attribute 'max_position_embeddings'
2025-06-11 01:04:54,647 - hace_core.models.model_loader - INFO - Preparing model for baseline testing with default KV cache
2025-06-11 01:04:54,648 - __main__ - INFO - Loading dataset hotpotqa...
2025-06-11 01:04:54,648 - __main__ - INFO - 尝试从本地JSONL文件加载数据集: hotpotqa
2025-06-11 01:04:55,036 - __main__ - INFO - ✅ 从本地加载 hotpotqa，共 7405 条样本
2025-06-11 01:04:55,038 - __main__ - INFO - ✅ 成功从本地JSONL文件加载 hotpotqa (来源: local)
2025-06-11 01:04:55,040 - hace_core.data.dataset_loader - INFO - Preparing 1 samples from hotpotqa
2025-06-11 01:04:55,040 - hace_core.data.dataset_loader - INFO - Prepared 1 samples successfully
2025-06-11 01:04:55,041 - __main__ - INFO - Preparing batch with size 1, max_length 512...
2025-06-11 01:04:55,211 - __main__ - INFO - 输入数据验证通过
2025-06-11 01:04:55,213 - __main__ - INFO - Warming up FullKVCache model...
2025-06-11 01:04:56,812 - hace_core.utils.unified_monitor - INFO - 启动统一监控
2025-06-11 01:04:56,814 - hace_core.utils.unified_monitor - INFO - GPU 0 峰值内存统计已重置
2025-06-11 01:04:56,819 - hace_core.utils.unified_monitor - INFO - 统一监控循环已启动
2025-06-11 01:04:56,819 - __main__ - INFO - Starting FullKVCache performance measurement...
2025-06-11 01:04:56,824 - hace_core.utils.unified_monitor - INFO - 开始生成计时
2025-06-11 01:04:57,050 - hace_core.utils.unified_monitor - INFO - 记录第一个令牌生成
2025-06-11 01:05:02,823 - hace_core.utils.unified_monitor - INFO - 结束生成计时，总时间: 6.00秒
2025-06-11 01:05:02,823 - __main__ - INFO - 开始自动评分...
2025-06-11 01:05:02,826 - __main__ - INFO - 样本 1 评分: 0.000
2025-06-11 01:05:02,826 - __main__ - WARNING - ⚠️ 发现 1 个样本的ground truth为Unknown，评分可能无效
2025-06-11 01:05:02,826 - __main__ - WARNING - 请检查数据集格式和答案提取逻辑
2025-06-11 01:05:02,827 - __main__ - INFO - ✅ 评分完成! 平均分数: 0.000 (1/1 个样本)
2025-06-11 01:05:02,827 - hace_core.utils.unified_monitor - INFO - 停止统一监控
2025-06-11 01:05:02,828 - hace_core.utils.unified_monitor - INFO - GPU 0 最终内存状态: 当前分配=12860.7MB, 最终峰值=13215.2MB
2025-06-11 01:05:02,854 - hace_core.utils.unified_monitor - INFO - 设备 0 统计: 峰值=13215.2MB, 平均=13119.9MB, 样本=54
2025-06-11 01:05:02,855 - hace_core.utils.unified_monitor - INFO - GPU统计摘要: 总峰值内存 13215.2MB
2025-06-11 01:05:02,855 - hace_core.utils.unified_monitor - INFO - 设备 0 统计: 峰值=13215.2MB, 平均=13119.9MB, 样本=54
2025-06-11 01:05:02,856 - hace_core.utils.unified_monitor - INFO - GPU统计摘要: 总峰值内存 13215.2MB
2025-06-11 01:05:02,858 - hace_core.utils.unified_monitor - INFO - 统一监控指标已保存到: results\fullkvcache_experiments\fullkvcache_run_20250611_010409\ds_hotpotqa_kv512_bs1_rep0\fullkvcache_metrics_fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410.json
2025-06-11 01:05:02,860 - __main__ - INFO - 评分结果已保存到: results\fullkvcache_experiments\fullkvcache_run_20250611_010409\ds_hotpotqa_kv512_bs1_rep0\evaluation_results_fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410.json
2025-06-11 01:05:02,861 - __main__ - INFO - FullKVCache Experiment fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410 completed. Metrics: {'experiment_id': 'fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410', 'timestamp': '2025-06-11T01:05:02.855405', 'performance': {'success': True, 'ttft_ms': 225.44026374816895, 'tpot_ms': 117.76658466884068, 'throughput_tokens_per_sec': 8.33444378336293, 'total_time_sec': 5.9992005825042725, 'tokens_generated': 50, 'model_name': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'batch_size': 1, 'kv_cache_length': 512, 'max_new_tokens': 50, 'use_fullkvcache': True, 'dataset': 'hotpotqa', 'repetition': 0}, 'gpu': {'total_devices': 1, 'device_0': {'peak_memory_mb': 13215.1787109375, 'average_memory_mb': 13119.911331741898, 'sample_count': 54}, 'total_peak_memory_mb': 13215.1787109375}, 'system': {'peak_cpu_percent': 32.2, 'average_cpu_percent': 22.816666666666666, 'peak_memory_percent': 23.5, 'peak_memory_used_gb': 15.026908874511719, 'sample_count': 6}, 'monitoring_duration': 6.041313886642456}
2025-06-11 01:05:02,862 - __main__ - INFO - 开始清理实验 fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410 的资源...
2025-06-11 01:05:03,352 - __main__ - INFO - 实验 fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010410 资源清理完成
2025-06-11 01:05:03,367 - __main__ - INFO - ✓ 实验成功完成: ds_hotpotqa_kv512_bs1_rep0
2025-06-11 01:05:03,537 - __main__ - INFO - All FullKVCache experiment summaries saved to results\fullkvcache_experiments\fullkvcache_run_20250611_010409\all_fullkvcache_experiments_summary.csv
2025-06-11 01:05:03,538 - __main__ - INFO - 开始处理基线评分...
2025-06-11 01:05:03,539 - __main__ - WARNING - 未找到有效的评分结果，无法建立基线
2025-06-11 01:05:03,539 - __main__ - INFO - FullKVCache experiment suite finished.
