experiment_id,timestamp,performance,gpu,system,monitoring_duration
fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_004947,2025-06-11T00:50:42.808047,"{'success': True, 'ttft_ms': 251.86920166015625, 'tpot_ms': 133.10272353036063, 'throughput_tokens_per_sec': 7.376727531103474, 'total_time_sec': 6.778073310852051, 'tokens_generated': 50, 'model_name': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'batch_size': 1, 'kv_cache_length': 512, 'max_new_tokens': 50, 'use_fullkvcache': True, 'dataset': 'hotpotqa', 'repetition': 0}","{'total_devices': 1, 'device_0': {'peak_memory_mb': 13215.1787109375, 'average_memory_mb': 13121.14587602459, 'sample_count': 61}, 'total_peak_memory_mb': 13215.1787109375}","{'peak_cpu_percent': 46.2, 'average_cpu_percent': 30.2, 'peak_memory_percent': 23.3, 'peak_memory_used_gb': 14.884746551513672, 'sample_count': 7}",6.822299480438232
