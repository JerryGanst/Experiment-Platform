experiment_id,timestamp,performance,gpu,system,monitoring_duration
fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_000133,2025-06-11T00:03:15.968852,"{'success': True, 'ttft_ms': 196.11263275146484, 'tpot_ms': 170.55371450999425, 'throughput_tokens_per_sec': 5.847552951322611, 'total_time_sec': 10.944749116897583, 'tokens_generated': 64, 'model_name': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'batch_size': 1, 'kv_cache_length': 512, 'max_new_tokens': 64, 'use_fullkvcache': True, 'dataset': 'hotpotqa', 'repetition': 0}","{'total_devices': 1, 'device_0': {'peak_memory_mb': 13215.1787109375, 'average_memory_mb': 13128.570055774806, 'sample_count': 97}, 'total_peak_memory_mb': 13215.1787109375}","{'peak_cpu_percent': 60.8, 'average_cpu_percent': 45.300000000000004, 'peak_memory_percent': 22.0, 'peak_memory_used_gb': 14.05459213256836, 'sample_count': 11}",10.97166109085083
