2025-06-12 22:05:58,155 - __main__ - INFO - Starting FullKVCache experiment suite with run name: fullkvcache_run_20250612_220558
2025-06-12 22:05:58,155 - __main__ - INFO - Arguments: Namespace(model_name='mistralai/Mistral-7B-Instruct-v0.3', datasets='hotpotqa', kv_cache_lengths='128', batch_sizes='1', max_new_tokens=10, repetitions=1, output_dir='results\\fullkvcache_experiments', log_level='INFO', seed=42, run_name='fullkvcache_run_20250612_220558', enable_scoring=True, is_baseline_run=True)
2025-06-12 22:05:58,156 - __main__ - INFO - Global EXPERIMENT_CONFIG being used: {'model_name_or_path': 'mistralai/Mistral-7B-Instruct-v0.3', 'precision': 'fp16', 'multi_model_experiments': True, 'experiment_models': ['NousResearch/Llama-2-7b-hf', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'mistralai/Mistral-7B-Instruct-v0.3'], 'memory_management': {'auto_max_memory': True, 'manual_max_memory': {0: '23000MB'}, 'memory_buffer_ratio': 0.05, 'force_no_cpu_offload': True}, 'datasets': ['mmlu', 'gsm8k', 'winogrande', 'arc_challenge', 'hellaswag', 'truthful_qa_mc'], 'dataset_subset_size': {'mmlu': 100, 'gsm8k': 100, 'winogrande': None, 'arc_challenge': None, 'hellaswag': None, 'truthful_qa_mc': None, 'pubmed_qa': 100, 'cais/mmlu-zh': 50}, 'kv_cache_lengths': [128, 256, 512, 1024, 2048], 'batch_sizes': [1, 4, 8], 'max_new_tokens': 256, 'repetitions': 3, 'h2o_enabled': True, 'h2o_ratios': [0.1, 0.2, 0.3], 'eviction_strategies': ['attention', 'time_decay', 'hybrid'], 'h2o_kv_cache_lengths': [128, 256, 512, 1024, 2048], 'cake_enabled': True, 'layer_allocation_strategies': ['uniform', 'adaptive', 'attention_based'], 'layer_analysis_configs': {'attention_pattern_analysis': True, 'layer_importance_scoring': True, 'dynamic_allocation': True}, 'cache_budgets': [0.5, 0.7, 0.9], 'cake_kv_cache_lengths': [128, 256, 512, 1024, 2048], 'head_level_optimization': False, 'head_analysis_enabled': False, 'head_selection_strategy': 'top_k', 'head_k_value': 10, 'output_base_dir': 'results', 'enable_monitoring': True, 'monitor_interval': 0.5}
2025-06-12 22:05:58,157 - __main__ - INFO - Random seed set to 42
2025-06-12 22:05:58,157 - __main__ - INFO - Total number of FullKVCache experiment configurations to run: 1
2025-06-12 22:05:58,158 - __main__ - INFO - Running FullKVCache: Rep 1/1, Dataset: hotpotqa, KV_Len: 128, Batch: 1
2025-06-12 22:05:58,205 - __main__ - INFO - Starting FullKVCache experiment: fullkvcache_hotpotqa_kv128_bs1_rep0_20250612_220558
2025-06-12 22:05:58,252 - __main__ - INFO - 实验前内存清理完成
2025-06-12 22:05:58,252 - hace_core.utils.unified_monitor - WARNING - 没有可用的GPU设备
2025-06-12 22:05:58,252 - hace_core.utils.unified_monitor - INFO - 统一监控器初始化完成，实验ID: fullkvcache_hotpotqa_kv128_bs1_rep0_20250612_220558
2025-06-12 22:05:58,252 - hace_core.utils.unified_monitor - INFO - 记录实验配置
2025-06-12 22:05:58,252 - __main__ - INFO - Loading model and tokenizer...
2025-06-12 22:05:58,252 - hace_core.models.model_loader - INFO - Loading model: mistralai/Mistral-7B-Instruct-v0.3
2025-06-12 22:06:00,526 - hace_core.models.model_loader - ERROR - Error loading model: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):
operator torchvision::nms does not exist
2025-06-12 22:06:00,526 - __main__ - ERROR - 运行时错误 - 实验 fullkvcache_hotpotqa_kv128_bs1_rep0_20250612_220558: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):
operator torchvision::nms does not exist
Traceback (most recent call last):
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\utils\import_utils.py", line 1980, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\mistral\modeling_mistral.py", line 27, in <module>
    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\modeling_utils.py", line 68, in <module>
    from .loss.loss_utils import LOSS_MAPPING
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\loss\loss_utils.py", line 21, in <module>
    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\loss\loss_deformable_detr.py", line 4, in <module>
    from ..image_transforms import center_to_corners_format
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\image_transforms.py", line 21, in <module>
    from .image_utils import (
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\image_utils.py", line 65, in <module>
    from torchvision import io as torchvision_io
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torchvision\__init__.py", line 10, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torchvision\_meta_registrations.py", line 163, in <module>
    @torch.library.register_fake("torchvision::nms")
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\library.py", line 1023, in register
    use_lib._register_fake(op_name, func, _stacklevel=stacklevel + 1)
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\library.py", line 214, in _register_fake
    handle = entry.fake_impl.register(func_to_register, source)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\_library\fake_impl.py", line 31, in register
    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, "Meta"):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: operator torchvision::nms does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\JerryGanst\PycharmProjects\Experiment-Platform\hace-kv-optimization\baselines\fullkvcache_main.py", line 491, in run_fullkvcache_experiment
    model, tokenizer = load_model_and_tokenizer(model_config)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\PycharmProjects\Experiment-Platform\hace-kv-optimization\hace_core\models\model_loader.py", line 82, in load_model_and_tokenizer
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 568, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 388, in _get_model_class
    supported_models = model_mapping[type(config)]
                       ~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 774, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 788, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 700, in getattribute_from_module
    if hasattr(module, attr):
       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\utils\import_utils.py", line 1968, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\utils\import_utils.py", line 1982, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):
operator torchvision::nms does not exist
2025-06-12 22:06:00,532 - hace_core.utils.unified_monitor - ERROR - 实验标记为失败: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):
operator torchvision::nms does not exist
2025-06-12 22:06:00,533 - __main__ - INFO - 开始清理实验 fullkvcache_hotpotqa_kv128_bs1_rep0_20250612_220558 的资源...
2025-06-12 22:06:00,602 - __main__ - INFO - 实验 fullkvcache_hotpotqa_kv128_bs1_rep0_20250612_220558 资源清理完成
2025-06-12 22:06:00,602 - __main__ - INFO - ✓ 实验成功完成: ds_hotpotqa_kv128_bs1_rep0
2025-06-12 22:06:00,671 - __main__ - INFO - All FullKVCache experiment summaries saved to results\fullkvcache_experiments\fullkvcache_run_20250612_220558\all_fullkvcache_experiments_summary.csv
2025-06-12 22:06:00,671 - __main__ - INFO - 开始处理基线评分...
2025-06-12 22:06:00,671 - __main__ - WARNING - 未找到有效的评分结果，无法建立基线
2025-06-12 22:06:00,671 - __main__ - INFO - FullKVCache experiment suite finished.
