experiment_id,timestamp,performance,gpu,system,monitoring_duration
fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_010800,2025-06-11T01:08:55.111218,"{'success': True, 'ttft_ms': 203.39655876159668, 'tpot_ms': 131.6176579923046, 'throughput_tokens_per_sec': 7.510308108739947, 'total_time_sec': 6.6575164794921875, 'tokens_generated': 50, 'model_name': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'batch_size': 1, 'kv_cache_length': 512, 'max_new_tokens': 50, 'use_fullkvcache': True, 'dataset': 'hotpotqa', 'repetition': 0}","{'total_devices': 1, 'device_0': {'peak_memory_mb': 13215.1787109375, 'average_memory_mb': 13120.355328058793, 'sample_count': 59}, 'total_peak_memory_mb': 13215.1787109375}","{'peak_cpu_percent': 28.0, 'average_cpu_percent': 23.8, 'peak_memory_percent': 23.7, 'peak_memory_used_gb': 15.15728759765625, 'sample_count': 7}",6.700904607772827
