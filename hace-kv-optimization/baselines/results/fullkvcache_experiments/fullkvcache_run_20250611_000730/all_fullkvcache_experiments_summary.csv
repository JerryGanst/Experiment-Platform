experiment_id,timestamp,performance,gpu,system,monitoring_duration
fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_000731,2025-06-11T00:08:26.117205,"{'success': True, 'ttft_ms': 216.6128158569336, 'tpot_ms': 119.5560031467014, 'throughput_tokens_per_sec': 8.255447883619956, 'total_time_sec': 7.752456426620483, 'tokens_generated': 64, 'model_name': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'batch_size': 1, 'kv_cache_length': 512, 'max_new_tokens': 64, 'use_fullkvcache': True, 'dataset': 'hotpotqa', 'repetition': 0}","{'total_devices': 1, 'device_0': {'peak_memory_mb': 13215.1787109375, 'average_memory_mb': 13125.645812103714, 'sample_count': 69}, 'total_peak_memory_mb': 13215.1787109375}","{'peak_cpu_percent': 33.3, 'average_cpu_percent': 24.75, 'peak_memory_percent': 22.8, 'peak_memory_used_gb': 14.589286804199219, 'sample_count': 8}",7.784801244735718
