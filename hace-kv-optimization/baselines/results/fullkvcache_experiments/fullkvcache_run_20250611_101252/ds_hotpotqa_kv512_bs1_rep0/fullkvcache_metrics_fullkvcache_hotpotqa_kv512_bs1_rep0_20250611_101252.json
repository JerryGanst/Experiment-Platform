{
  "experiment_id": "fullkvcache_hotpotqa_kv512_bs1_rep0_20250611_101252",
  "timestamp": "2025-06-11T10:13:32.108751",
  "performance": {
    "success": true,
    "ttft_ms": 3090.958595275879,
    "tpot_ms": 1132.4754291110569,
    "throughput_tokens_per_sec": 0.7526018776648008,
    "total_time_sec": 13.287237644195557,
    "tokens_generated": 10,
    "model_name": "NousResearch/Llama-2-7b-hf",
    "precision": "fp16",
    "batch_size": 1,
    "kv_cache_length": 512,
    "max_new_tokens": 10,
    "use_fullkvcache": true,
    "dataset": "hotpotqa",
    "repetition": 0
  },
  "gpu": {
    "total_devices": 1,
    "device_0": {
      "peak_memory_mb": 10419.4765625,
      "average_memory_mb": 10197.181525735294,
      "sample_count": 119
    },
    "total_peak_memory_mb": 10419.4765625
  },
  "system": {
    "peak_cpu_percent": 13.7,
    "average_cpu_percent": 10.72857142857143,
    "peak_memory_percent": 42.8,
    "peak_memory_used_gb": 27.324607849121094,
    "sample_count": 14
  },
  "monitoring_duration": 13.385237693786621
}