2025-06-04 09:57:36,228 - __main__ - INFO - Starting CAKE experiment suite with run name: cake_run_20250604_095736
2025-06-04 09:57:36,228 - __main__ - INFO - Arguments: Namespace(model_name='huggyllama/llama-7b', datasets='mmlu', kv_cache_lengths='512', batch_sizes='1', max_new_tokens=32, allocation_strategies='adaptive', cache_budgets='0.8', repetitions=1, output_dir='results\\cake_experiments', log_level='INFO', seed=42, run_name='cake_run_20250604_095736')
2025-06-04 09:57:36,229 - __main__ - INFO - Global EXPERIMENT_CONFIG being used: {'model_name_or_path': 'NousResearch/Llama-2-7b-hf', 'precision': 'fp16', 'datasets': ['mmlu', 'gsm8k', 'winogrande', 'arc_challenge', 'hellaswag', 'truthful_qa_mc'], 'dataset_subset_size': {'mmlu': 100, 'gsm8k': 100, 'winogrande': None, 'arc_challenge': None, 'hellaswag': None, 'truthful_qa_mc': None, 'pubmed_qa': 100, 'cais/mmlu-zh': 50}, 'kv_cache_lengths': [512, 1024, 2048], 'batch_sizes': [1, 4, 8], 'max_new_tokens': 256, 'repetitions': 3, 'h2o_enabled': True, 'h2o_ratios': [0.1, 0.2, 0.3], 'eviction_strategies': ['attention', 'time_decay', 'hybrid'], 'h2o_kv_cache_lengths': [512, 1024], 'cake_enabled': True, 'layer_allocation_strategies': ['uniform', 'adaptive', 'attention_based'], 'layer_analysis_configs': {'attention_pattern_analysis': True, 'layer_importance_scoring': True, 'dynamic_allocation': True}, 'cache_budgets': [0.5, 0.7, 0.9], 'cake_kv_cache_lengths': [512, 1024], 'head_level_optimization': False, 'head_analysis_enabled': False, 'head_selection_strategy': 'top_k', 'head_k_value': 10, 'output_base_dir': 'results', 'enable_monitoring': True, 'monitor_interval': 0.5}
2025-06-04 09:57:36,229 - __main__ - INFO - Global CAKE_MODEL_CONFIG being used: {'default_allocation_strategy': 'adaptive', 'default_cache_budget': 0.8, 'supported_models_cake': ['llama', 'mistral', 'qwen2'], 'dynamic_allocation_default': True, 'layer_analysis_default': {'attention_pattern_analysis': True, 'layer_importance_scoring': True}}
2025-06-04 09:57:36,251 - __main__ - INFO - Random seed set to 42
2025-06-04 09:57:36,251 - __main__ - INFO - Total number of CAKE experiment configurations to run: 1
2025-06-04 09:57:36,252 - __main__ - INFO - Running CAKE: Rep 1/1, Dataset: mmlu, KV_Len: 512, Batch: 1, Strategy: adaptive, Budget: 0.8
2025-06-04 09:57:36,252 - __main__ - INFO - Starting CAKE experiment: cake_mmlu_kv512_bs1_stratadaptive_bud0.8_rep0_20250604_095736
2025-06-04 09:57:36,252 - metrics.metrics_collector - INFO - Performance metrics collector initialized with ID: cake_mmlu_kv512_bs1_stratadaptive_bud0.8_rep0_20250604_095736
2025-06-04 09:57:36,253 - metrics.metrics_collector - INFO - Recorded experiment config
2025-06-04 09:57:36,253 - __main__ - INFO - Loading model and tokenizer...
2025-06-04 09:57:36,253 - models.model_loader - INFO - Loading model: huggyllama/llama-7b
2025-06-04 09:57:42,797 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-04 09:57:45,776 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-06-04 09:57:45,776 - models.model_loader - INFO - Model loaded successfully with dtype: torch.float16
2025-06-04 09:57:46,388 - models.model_loader - INFO - Tokenizer loaded successfully
2025-06-04 09:57:46,388 - models.model_loader - INFO - 模型类型 'llama' 被CAKE支持。
2025-06-04 09:57:46,398 - models.model_loader - INFO - Preparing model for CAKE testing with experiment config: {'layer_allocation_strategies': ['adaptive'], 'cache_budgets': [0.8], 'layer_analysis_configs': {'attention_pattern_analysis': True, 'layer_importance_scoring': True, 'dynamic_allocation': True}} and model specific config: {'default_allocation_strategy': 'adaptive', 'default_cache_budget': 0.8, 'supported_models_cake': ['llama', 'mistral', 'qwen2'], 'dynamic_allocation_default': True, 'layer_analysis_default': {'attention_pattern_analysis': True, 'layer_importance_scoring': True}}
2025-06-04 09:57:46,399 - models.cake_converter - INFO - CAKE实验配置初始化: 策略=adaptive, 预算=0.8, 窗口=32
2025-06-04 09:57:46,399 - models.cake_converter - INFO - 开始为 llama 模型应用CAKE
2025-06-04 09:57:46,399 - models.cake_converter - INFO - 模型配置完成: 32层, 预算分配=[100, 97, 94, 90, 87]...
2025-06-04 09:57:46,399 - models.cake_converter - INFO - 应用 llama 的CAKE补丁
2025-06-04 09:57:46,399 - models.cake_converter - INFO - CAKE应用完成！
2025-06-04 09:57:46,399 - models.model_loader - INFO - Model successfully prepared for CAKE testing.
2025-06-04 09:57:46,400 - __main__ - INFO - Loading dataset mmlu...
2025-06-04 09:57:46,400 - data.dataset_loader - INFO - Loading dataset: cais/mmlu (subset: all) - split: validation
2025-06-04 09:58:35,057 - data.dataset_loader - INFO - Dataset loaded successfully with 1531 samples
2025-06-04 09:58:35,057 - data.dataset_loader - INFO - Preparing 1 samples from mmlu
2025-06-04 09:58:35,058 - data.dataset_loader - INFO - Prepared 1 samples successfully
2025-06-04 09:58:35,058 - __main__ - INFO - Preparing batch with size 1, max_length 2048...
2025-06-04 09:58:35,061 - __main__ - INFO - Warming up CAKE model...
2025-06-04 09:58:35,537 - __main__ - ERROR - Error during CAKE experiment cake_mmlu_kv512_bs1_stratadaptive_bud0.8_rep0_20250604_095736: tuple index out of range
Traceback (most recent call last):
  File "C:\Users\JerryGanst\PycharmProjects\PythonProject1\Research Framework for Optimizing Head-level KV Cache Based on CAKE\cake_main.py", line 223, in run_cake_experiment
    _ = model.generate(
        ^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2452, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 3418, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\accelerate\hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\utils\generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 826, in forward
    outputs: BaseModelOutputWithPast = self.model(
                                       ^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\JerryGanst\PycharmProjects\PythonProject1\Research Framework for Optimizing Head-level KV Cache Based on CAKE\cakekv-main\cakekv-main\cake\model\modify_llama.py", line 291, in llama_model_forward_cake
    next_decoder_cache = layer_outputs[2 if output_attentions else 1]
                         ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: tuple index out of range
2025-06-04 09:58:35,541 - metrics.metrics_collector - ERROR - Experiment marked as failed: tuple index out of range
2025-06-04 09:58:35,549 - __main__ - INFO - Cleaned up resources for experiment cake_mmlu_kv512_bs1_stratadaptive_bud0.8_rep0_20250604_095736
2025-06-04 09:58:35,552 - __main__ - INFO - All CAKE experiment summaries saved to results\cake_experiments\cake_run_20250604_095736\all_cake_experiments_summary.csv
2025-06-04 09:58:35,552 - __main__ - INFO - CAKE experiment suite finished.
